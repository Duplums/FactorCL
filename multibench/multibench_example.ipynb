{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# FactorCL on Multibench Datasets"
      ],
      "metadata": {
        "id": "LTEV_elPBK32"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWNBW_QzYrvs"
      },
      "source": [
        "##Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgGoqg0DYP92",
        "outputId": "8db4a419-7304-4ecc-b552-b0c44344c123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MultiBench'...\n",
            "remote: Enumerating objects: 6925, done.\u001b[K\n",
            "remote: Counting objects: 100% (136/136), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 6925 (delta 62), reused 123 (delta 60), pack-reused 6789\u001b[K\n",
            "Receiving objects: 100% (6925/6925), 51.06 MiB | 17.93 MiB/s, done.\n",
            "Resolving deltas: 100% (4248/4248), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pliang279/MultiBench"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1KGIlFvYqYH",
        "outputId": "f3a508b7-669f-4a5d-b9c7-45a65a53f641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MultiBench\n"
          ]
        }
      ],
      "source": [
        "%cd MultiBench/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3RpE80CYxIY",
        "outputId": "87d45666-050d-46ea-aa5c-7a90bf7923ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1EMBUmUL5B0PTncGx3L-sBElGOmjFBR_h\n",
            "To: /content/MultiBench/sarcasm.pkl\n",
            "100% 208M/208M [00:01<00:00, 189MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown\n",
        "#!gdown https://drive.google.com/uc?id=1_XdzdW8UNG1TTS6QcX10uhoS6N11OBit&export=download #MOSI data\n",
        "#!gdown https://drive.google.com/u/0/uc?id=1KvKynJJca5tDtI5Mmp6CoRh9pQywH8Xp&export=download #AVMNIST\n",
        "#!gdown https://drive.google.com/uc?id=180l4pN6XAv8-OAYQ6OrMheFUMwtqUWbz&export=download #MOSEI data\n",
        "!gdown https://drive.google.com/uc?id=1EMBUmUL5B0PTncGx3L-sBElGOmjFBR_h&export=download #Sarcasm data\n",
        "#!gdown https://drive.google.com/uc?id=1L5slPmYyhEVtwGyM1kgcFMjeBpXLZGT0&export=download #Humor data\n",
        "\n",
        "#!sh /content/MultiBench/datasets/enrico/download_data.sh #Enrico"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pliang279/FactorCL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHKnbVkoASPI",
        "outputId": "8e0fe866-1205-4a2c-df8e-d12e89123883"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FactorCL'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 37 (delta 14), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (37/37), 20.62 KiB | 1.87 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from unimodals.common_models import Transformer, MLP"
      ],
      "metadata": {
        "id": "A0mgHF3bAgvo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets.affect.get_data import get_dataloader\n",
        "\n",
        "# Create the training, validation, and test-set dataloaders. \n",
        "train_loader, valid_loader, test_loader = get_dataloader('/content/MultiBench/sarcasm.pkl', batch_size=128, data_type='sarcasm')"
      ],
      "metadata": {
        "id": "5RWziN1_ANhB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append(os.getcwd())\n",
        "#sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))"
      ],
      "metadata": {
        "id": "ZBH2aOwge2Lb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd FactorCL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9fKJqfVdYbH",
        "outputId": "6c6e64ec-971a-4bf1-b21a-5eee2269b4dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MultiBench/FactorCL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from multibench_model import*"
      ],
      "metadata": {
        "id": "r2H_R1qlgQKt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgpMeb4eRI5Z"
      },
      "source": [
        "##FactorCL-SUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ha5JwFzHRKjd"
      },
      "outputs": [],
      "source": [
        "encoders = [Transformer(371, 40).cuda(), Transformer(300, 40).cuda()]\n",
        "rus_model = RUSModel(encoders=encoders, feat_dims=[40, 40], y_ohe_dim=3).cuda()\n",
        "train_rusmodel_sarcasm(rus_model, train_loader, num_epoch=100, num_club_iter=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_embeds_x1 = np.concatenate([rus_model.get_embedding(data[0][0].cuda(), data[0][2].cuda())[0].detach().cpu().numpy() for data in train_loader])\n",
        "train_embeds_x2 = np.concatenate([rus_model.get_embedding(data[0][0].cuda(), data[0][2].cuda())[1].detach().cpu().numpy() for data in train_loader])\n",
        "train_embeds = np.concatenate([train_embeds_x1, train_embeds_x2], axis=1)\n",
        "train_labels = np.concatenate([data[3].detach().cpu().numpy() for data in train_loader])\n",
        "train_labels = sarcasm_label(train_labels)\n",
        "  \n",
        "test_embeds_x1 = np.concatenate([rus_model.get_embedding(data[0][0].cuda(), data[0][2].cuda())[0].detach().cpu().numpy() for data in test_loader])\n",
        "test_embeds_x2 = np.concatenate([rus_model.get_embedding(data[0][0].cuda(), data[0][2].cuda())[1].detach().cpu().numpy() for data in test_loader])\n",
        "test_embeds = np.concatenate([test_embeds_x1, test_embeds_x2], axis=1)\n",
        "test_labels = np.concatenate([data[3].detach().cpu().numpy() for data in test_loader])\n",
        "test_labels = sarcasm_label(test_labels)\n",
        "\n",
        "clf = LogisticRegression(max_iter=200).fit(train_embeds, train_labels)\n",
        "score = clf.score(test_embeds, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cCSnp8_Zv6I",
        "outputId": "1dc31f6f-8101-47a9-9a11-9955159a8a54"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score"
      ],
      "metadata": {
        "id": "oTEJEZ1wdE_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bvQGiz2nq_J"
      },
      "source": [
        "##SimCLR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7cS_0F7IYnr"
      },
      "outputs": [],
      "source": [
        "encoders = [Transformer(371, 40).cuda(), Transformer(300, 40).cuda()] #must have the same feature dim\n",
        "supcon_model = SupConResNet(temperature=0.5, encoders=encoders, dim_ins=[40, 40], feat_dims=[40, 40]).cuda()\n",
        "supcon_optim = optim.Adam(supcon_model.parameters())\n",
        "train_supcon_sarcasm(supcon_model, train_loader, supcon_optim, modalities=[0,2], num_epoch=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOTa0qKhIYnr"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_embeds_x1 = np.concatenate([supcon_model.get_embedding(data[0][0].cuda(), data[0][2].cuda())[0].detach().cpu().numpy() for data in train_loader])\n",
        "train_embeds_x2 = np.concatenate([supcon_model.get_embedding(data[0][0].cuda(), data[0][2].cuda())[1].detach().cpu().numpy() for data in train_loader])\n",
        "train_embeds = np.concatenate([train_embeds_x1, train_embeds_x2], axis=1)\n",
        "train_labels = np.concatenate([data[3].detach().cpu().numpy() for data in train_loader])\n",
        "train_labels = sarcasm_label(train_labels)\n",
        "  \n",
        "test_embeds_x1 = np.concatenate([supcon_model.get_embedding(data[0][0].cuda(), data[0][2].cuda())[0].detach().cpu().numpy() for data in test_loader])\n",
        "test_embeds_x2 = np.concatenate([supcon_model.get_embedding(data[0][0].cuda(), data[0][2].cuda())[1].detach().cpu().numpy() for data in test_loader])\n",
        "test_embeds = np.concatenate([test_embeds_x1, test_embeds_x2], axis=1)\n",
        "test_labels = np.concatenate([data[3].detach().cpu().numpy() for data in test_loader])\n",
        "test_labels = sarcasm_label(test_labels)\n",
        "\n",
        "clf = LogisticRegression(max_iter=100).fit(train_embeds, train_labels)\n",
        "score = clf.score(test_embeds, test_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score"
      ],
      "metadata": {
        "id": "zxpn6JcEWQc1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}