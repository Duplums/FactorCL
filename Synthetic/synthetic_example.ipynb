{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#FactorCL on Synthetic Dataset"
      ],
      "metadata": {
        "id": "LTEV_elPBK32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pliang279/FactorCL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHKnbVkoASPI",
        "outputId": "fe91ef3e-6a93-45d1-8adb-bd88a400ad21"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FactorCL'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 34 (delta 12), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (34/34), 19.92 KiB | 1.99 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd FactorCL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_UCHEyzAbYQ",
        "outputId": "321c7d66-c807-4276-97c7-b1bce963a195"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/FactorCL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Synthetic.dataset import*\n",
        "from synthetic_models import*\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "A0mgHF3bAgvo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "A_dim, B_dim = 100, 100\n",
        "x1_dim, x2_dim = 100, 100\n",
        "y_dim = 1\n",
        "label_dim = 1\n",
        "#estimator = 'probabilistic_classifier'\n",
        "lr = 1e-4\n",
        "relative_ratio = 0.001\n",
        "hidden_dim=512 \n",
        "embed_dim=128\n",
        "layers=1\n",
        "activation = 'relu'"
      ],
      "metadata": {
        "id": "5RWziN1_ANhB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glk_GDn0AEvs",
        "outputId": "e93ee388-c4d9-4638-e061-7a5e5f9c8560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1', '2', '12']\n",
            "{'12': 10, '1': 6, '2': 6}\n",
            "{'12': 10, '1': 6, '2': 6}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define custom dimensions of features and labels\n",
        "feature_dim_info = dict()\n",
        "label_dim_info = dict()\n",
        "\n",
        "intersections = get_intersections(num_modalities=2)\n",
        "\n",
        "feature_dim_info['12'] = 10\n",
        "feature_dim_info['1'] = 6\n",
        "feature_dim_info['2'] = 6\n",
        "\n",
        "label_dim_info['12'] = 10\n",
        "label_dim_info['1'] = 6\n",
        "label_dim_info['2'] = 6\n",
        "\n",
        "print(intersections)\n",
        "print(feature_dim_info)\n",
        "print(label_dim_info)\n",
        "\n",
        "# Get datasets\n",
        "total_data, total_labels, total_raw_features = generate_data(30000, 2, feature_dim_info, label_dim_info)\n",
        "total_labels = get_labels(label_dim_info, total_raw_features)\n",
        "\n",
        "dataset = MultimodalDataset(total_data, total_labels)\n",
        "\n",
        "# Dataloader\n",
        "batch_size = 256\n",
        "num_data = total_labels.shape[0]\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(0.8*num_data), num_data-int(0.8*num_data)])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, drop_last=True,\n",
        "                            batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, drop_last=False,\n",
        "                            batch_size=batch_size)\n",
        "data_loader = DataLoader(dataset, shuffle=False, drop_last=False,\n",
        "                            batch_size=batch_size)    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##FactorCL-SUP"
      ],
      "metadata": {
        "id": "UP_E2H4EBnsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the model\n",
        "rus_model = RUSModel(A_dim, B_dim, 20, hidden_dim, embed_dim).cuda()\n",
        "train_rusmodel(rus_model, train_loader, dataset, num_epoch=10, num_club_iter=1)\n",
        "rus_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUrkdAhgAPgJ",
        "outputId": "7d923a4d-ac25-49d4-9ffa-2f5936a1a80f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter:  0  i_batch:  0  loss:  -4.513189196586609e-06\n",
            "iter:  1  i_batch:  0  loss:  -3.0942587852478027\n",
            "iter:  2  i_batch:  0  loss:  -5.861406326293945\n",
            "iter:  3  i_batch:  0  loss:  -6.599287033081055\n",
            "iter:  4  i_batch:  0  loss:  -6.948007583618164\n",
            "iter:  5  i_batch:  0  loss:  -6.756012439727783\n",
            "iter:  6  i_batch:  0  loss:  -6.895827293395996\n",
            "iter:  7  i_batch:  0  loss:  -7.467083930969238\n",
            "iter:  8  i_batch:  0  loss:  -7.240515232086182\n",
            "iter:  9  i_batch:  0  loss:  -7.031285762786865\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RUSModel(\n",
              "  (backbones): ModuleList(\n",
              "    (0-1): 2 x Sequential(\n",
              "      (0): Linear(in_features=100, out_features=512, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (3): ReLU()\n",
              "      (4): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (5): ReLU()\n",
              "      (6): Linear(in_features=512, out_features=128, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (linears_infonce_x1x2): ModuleList(\n",
              "    (0-1): 2 x Sequential(\n",
              "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (3): ReLU()\n",
              "      (4): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (linears_club_x1x2_cond): ModuleList(\n",
              "    (0-1): 2 x Sequential(\n",
              "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (3): ReLU()\n",
              "      (4): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (linears_infonce_x1y): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
              "  )\n",
              "  (linears_infonce_x2y): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
              "  )\n",
              "  (linears_infonce_x1x2_cond): ModuleList(\n",
              "    (0-1): 2 x Sequential(\n",
              "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (3): ReLU()\n",
              "      (4): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (linears_club_x1x2): ModuleList(\n",
              "    (0-1): 2 x Sequential(\n",
              "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (3): ReLU()\n",
              "      (4): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (infonce_x1x2): InfoNCECritic(\n",
              "    (_f): Sequential(\n",
              "      (0): Linear(in_features=256, out_features=512, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (3): ReLU()\n",
              "      (4): Linear(in_features=512, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (club_x1x2_cond): CLUBInfoNCECritic(\n",
              "    (_f): Sequential(\n",
              "      (0): Linear(in_features=276, out_features=512, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (3): ReLU()\n",
              "      (4): Linear(in_features=512, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (infonce_x1y): InfoNCECritic(\n",
              "    (_f): Sequential(\n",
              "      (0): Linear(in_features=129, out_features=512, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (3): ReLU()\n",
              "      (4): Linear(in_features=512, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (infonce_x2y): InfoNCECritic(\n",
              "    (_f): Sequential(\n",
              "      (0): Linear(in_features=129, out_features=512, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (3): ReLU()\n",
              "      (4): Linear(in_features=512, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (infonce_x1x2_cond): InfoNCECritic(\n",
              "    (_f): Sequential(\n",
              "      (0): Linear(in_features=276, out_features=512, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (3): ReLU()\n",
              "      (4): Linear(in_features=512, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (club_x1x2): CLUBInfoNCECritic(\n",
              "    (_f): Sequential(\n",
              "      (0): Linear(in_features=256, out_features=512, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (3): ReLU()\n",
              "      (4): Linear(in_features=512, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple evaluation using linear logistic regression model\n",
        "# Embeddings\n",
        "train_embeds = rus_model.get_embedding(torch.stack(train_dataset[:][:-1]).cuda()).detach().cpu().numpy()\n",
        "train_labels = train_dataset[:][-1].detach().cpu().numpy()\n",
        "\n",
        "test_embeds = rus_model.get_embedding(torch.stack(test_dataset[:][:-1]).cuda()).detach().cpu().numpy()\n",
        "test_labels = test_dataset[:][-1].detach().cpu().numpy()\n",
        "\n",
        "# Train Logistic Classifier\n",
        "clf = LogisticRegression(max_iter=200).fit(train_embeds, train_labels)\n",
        "score = clf.score(test_embeds, test_labels)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ril93KsbBeHZ",
        "outputId": "dd0a7728-c12d-4b16-b9e5-477ca59c02f0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9861666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SimCLR"
      ],
      "metadata": {
        "id": "6icituq2Hkra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simclr_model = SupConModel(A_dim, B_dim, hidden_dim, embed_dim, use_label=False).cuda()\n",
        "simclr_optim = optim.Adam(simclr_model.parameters(), lr=lr)\n",
        "train_supcon(simclr_model, train_loader, simclr_optim, num_epoch=10)\n",
        "simclr_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pYPGQgNHiPN",
        "outputId": "cf312ca1-c3d1-4bc8-d10c-8396f75cc9cf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter:  0  i_batch:  0  loss:  10.232044219970703\n",
            "iter:  1  i_batch:  0  loss:  5.859925270080566\n",
            "iter:  2  i_batch:  0  loss:  4.918781280517578\n",
            "iter:  3  i_batch:  0  loss:  4.062376976013184\n",
            "iter:  4  i_batch:  0  loss:  3.4061083793640137\n",
            "iter:  5  i_batch:  0  loss:  2.7391912937164307\n",
            "iter:  6  i_batch:  0  loss:  2.3390750885009766\n",
            "iter:  7  i_batch:  0  loss:  1.6201176643371582\n",
            "iter:  8  i_batch:  0  loss:  1.185381293296814\n",
            "iter:  9  i_batch:  0  loss:  0.9489563703536987\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SupConModel(\n",
              "  (encoder_x1): Sequential(\n",
              "    (0): Linear(in_features=100, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=512, out_features=128, bias=True)\n",
              "  )\n",
              "  (encoder_x2): Sequential(\n",
              "    (0): Linear(in_features=100, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=512, out_features=128, bias=True)\n",
              "  )\n",
              "  (projection_x1): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
              "  )\n",
              "  (projection_x2): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
              "  )\n",
              "  (critic): SupConLoss()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_embeds = simclr_model.get_embedding(torch.stack(train_dataset[:][:-1]).cuda()).detach().cpu().numpy()\n",
        "train_labels = train_dataset[:][-1].detach().cpu().numpy()\n",
        "\n",
        "# Embeddings\n",
        "test_embeds = simclr_model.get_embedding(torch.stack(test_dataset[:][:-1]).cuda()).detach().cpu().numpy()\n",
        "test_labels = test_dataset[:][-1].detach().cpu().numpy()\n",
        "\n",
        "# Train Logistic Classifier\n",
        "clf = LogisticRegression(max_iter=200).fit(train_embeds, train_labels)\n",
        "score = clf.score(test_embeds, test_labels)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvHpTE5gHoi6",
        "outputId": "e07fc494-f032-4a13-8ae8-eb7a4d8bd30f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    }
  ]
}